{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional Neural Networks .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Convolutional Neural Networks (CNNs)"
      ],
      "metadata": {
        "id": "qq5no2590tBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolving은 이미지와 필터 사이에 내적을 하는 것을 의미합니다. 따라서 이미지의 각 위치에 대해 단일 숫자를 얻습니다."
      ],
      "metadata": {
        "id": "PLl8I2MSv_pN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dUmunQVkHzU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcecd57-65d4-4af2-ede3-6c5b4574d762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 6, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Create 10 images with shape (1, 28, 28).\n",
        "Build 6 convolutional filters of size (3, 3) with stride set to 1 and padding set to 1.\n",
        "Apply the filters in the image and print the shape of the feature map.\n",
        "\n",
        "The arguments in Conv2d are in_channels, out_channels, kernel_size, stride, and padding.\n",
        "The number of in_channels is 1, while the number of out_channels is 6.\n",
        "'''\n",
        "\n",
        "# Convolution operator - OOP way\n",
        "import torch\n",
        "\n",
        "\n",
        "# Create 10 random images of shape (1, 28, 28)\n",
        "images = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Build 6 conv. filters\n",
        "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Convolve the image with the filters \n",
        "output_feature = conv_filters(images)\n",
        "print(output_feature.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolution operator - Functional way\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create 10 random images\n",
        "image = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = torch.rand(6, 1, 3, 3)\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
        "print(output_feature.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtJbH9iW1BDQ",
        "outputId": "7c3be4b3-771f-402d-9b20-74029d16263d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 6, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling operators\n",
        "- 컨볼루션은 이미지에서 특징을 추출하는 데 사용되는 반면 풀링은 특징 선택, 이미지에서 가장 지배적인 특징을 선택하거나 다른 특징을 결합하는 방법입니다. 또한 이미지의 해상도를 낮추어 계산을 보다 효율적으로 만듭니다.\n",
        "- Max-pooling: simply takes the maximum number in regions of images. \n",
        "- Average-Pooling: it takes the average value."
      ],
      "metadata": {
        "id": "QrujuqEd2S3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = max_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.max_pool2d(im, 2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "metadata": {
        "id": "f2iyhP1T2L4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = avg_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.avg_pool2d(im, 2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "metadata": {
        "id": "SAZBUD9944RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks\n",
        "- We first build a class called AlexNet which inherits from nn.Module. Then we start writing the __init__ method, where we pass the number of classes as an argument, in this case 1000. We call the superclass using the super operator, and then we start declaring all the parameters we want to have. In particular, we see that we have 5 convolutional layers, from conv_1 to conv_5, each with different number of filters. We got the numbers of filters from the paper. Then we want to have 3 pooling layers. They all have the same kernel_size and stride, so we define it only once. Similarly, we define once the ReLU nonlinearity. Finally, we have the three fully-connected layers, the last of which contains the number of classes.\n",
        "\n",
        "## calcuate numbers\n",
        "- Input Layer : All the input layer does is read the image. So, there are no parameters learn in here.\n",
        "- Convolutional Layer : Consider a convolutional layer which takes “l” feature maps as the input and has “k” feature maps as output. The filter size is “n*m”.\n",
        "Here the input has l=32 feature maps as inputs, k=64 feature maps as outputs and filter size is n=3 and m=3. It is important to understand, that we don’t simply have a 3*3 filter, but actually, we have 3*3*32 filter, as our input has 32 dimensions. And as an output from first conv layer, we learn 64 different 3*3*32 filters which total weights is “n*m*k*l”. Then there is a term called bias for each feature map. So, the total number of parameters are “(n*m*l+1)*k”.\n",
        "- Pooling Layer: There are no parameters you could learn in pooling layer. This layer is just used to reduce the image dimension size.\n",
        "- Fully-connected Layer: In this layer, all inputs units have a separable weight to each output unit. For “n” inputs and “m” outputs, the number of weights is “n*m”. Additionally, this layer has the bias for each output node, so “(n+1)*m” parameters.\n",
        "- Output Layer: This layer is the fully connected layer, so “(n+1)m” parameters, when “n” is the number of inputs and “m” is the number of outputs."
      ],
      "metadata": {
        "id": "tR999OVpS58G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## practice\n",
        "- Your first CNN - __init__ method\n",
        "You are going to build your first convolutional neural network. \n",
        "You're going to use the MNIST dataset as the dataset, which is made of handwritten digits from 0 to 9. \n",
        "- The convolutional neural network is going to have 2 convolutional layers, each followed by a ReLU nonlinearity, and a fully connected layer. \n",
        "We have already imported torch and torch.nn as nn. \n",
        "Remember that each pooling layer halves both the height and the width of the image, \n",
        "so by using 2 pooling layers, the height and width are 1/4 of the original sizes. MNIST images have shape (1, 28, 28)\n",
        "- For the moment, you are going to implement the __init__ method of the net. In the next exercise, you will implement the .forward() method.\n",
        "- NB: We need 2 pooling layers, but we only need to instantiate a pooling layer once, because each pooling layer will have the same configuration. Instead, we will use self.pool twice in the next exercise.\n",
        "- [Ref](https://stackoverflow.com/questions/42786717/how-to-calculate-the-number-of-parameters-for-convolutional-neural-network)"
      ],
      "metadata": {
        "id": "h26ql4RqTXSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Instantiate two convolutional filters: the first one should have 5 channels, while the second one should have 10 channels. \n",
        "The kernel_size for both of them should be 3, and both should use padding=1. Use the names of the arguments (instead of using 1, use padding=1).\n",
        "2. Instantiate a ReLU() nonlinearity.\n",
        "3. Instantiate a max pooling layer which halves the size of the image in both directions.\n",
        "4. Instantiate a fully connected layer which connects the units with the number of classes (we are using MNIST, so there are 10 classes).\n",
        "'''\n",
        "'''\n",
        "Hint\n",
        "Deduct the first size of the weights for the fully connected layers. Images start with shape (1, 28, 28) and two pooling operators (each halving the size of the image) are performed. What is the size of the image fed to the input layer (heigh * width * number_of_channels)?\n",
        "In line 16, number_of_channels is the same as the number of channels in self.conv2.\n",
        "MNIST images are black and white, so they contain one channel.\n",
        "'''\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(7 * 7 * 10, 10)"
      ],
      "metadata": {
        "id": "dWEiwzMITCbn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward\n",
        "'''\n",
        "Apply the first convolutional layer, followed by the relu nonlinearity, then in the next line apply max-pooling layer.\n",
        "Apply the second convolutional layer, followed by the relu nonlinearity, then in the next line apply max-pooling layer.\n",
        "Transform the feature map from 4 dimensional to 2 dimensional space. The first dimension contains the batch size (-1), deduct the second dimension, by multiplying the values for height, width and depth.\n",
        "Apply the fully-connected layer and return the result.\n",
        "'''\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\t\t\n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Prepare the image for the fully connected layer\n",
        "        x = x.view(-1, 7*7*10)\n",
        "\n",
        "        # Apply the fully connected layer and return the result\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "bnQWOIt-QaHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Convolutional Neural Networks\n"
      ],
      "metadata": {
        "id": "XUPiAXYLY3rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Compute the forward pass\n",
        "    outputs = net(inputs)\n",
        "        \n",
        "    # Compute the loss function\n",
        "    loss = criterion(outputs, labels)\n",
        "        \n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the weights\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "M-Cr9NpKY-NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the data in the test_loader\n",
        "for i, data in enumerate(test_loader):\n",
        "  \n",
        "    # Get the image and label from data\n",
        "    image, label = data\n",
        "    \n",
        "    # Make a forward pass in the net with your image\n",
        "    output = net(image)\n",
        "    \n",
        "    # Argmax the results of the net\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    if predicted == label:\n",
        "        print(\"Yipes, your net made the right prediction \" + str(predicted))\n",
        "    else:\n",
        "        print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))"
      ],
      "metadata": {
        "id": "RpbL7XdPZChn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}